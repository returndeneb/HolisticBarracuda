#pragma kernel LetterBoxImage
#pragma kernel PoseRegionUpdate
#pragma kernel CropImage
#pragma kernel PostProcess

#define PI 3.14159265359

#include "UnityCG.cginc"
#include "PoseRegion.cginc"
#include "LowPassFilter.cginc"
#include "Misc.cginc"
#include "Assets/jp.ikep.mediapipe.posedetection@1.0.1/ComputeShader/Common.cginc"


// Kernel 0
uint _isLinerColorSpace;
uint _letterboxWidth;
float2 _spadScale;
sampler2D _letterboxInput;
RWStructuredBuffer<float> _letterboxTextureBuffer;

// Generate letter-box image texture.
[numthreads(8, 8, 1)]
void LetterBoxImage(uint2 id : SV_DispatchThreadID)
{
    if (any(id > _letterboxWidth)) return;

    // UV coordinates
    float2 uv = float2(0.5 + id.x, _letterboxWidth - 0.5 - id.y) / _letterboxWidth;

    // Scaling
    uv = (uv - 0.5) * _spadScale + 0.5;

    // UV gradients
    float2 duv_dx = float2(+1.0 / _letterboxWidth * _spadScale.x, 0);
    float2 duv_dy = float2(0, -1.0 / _letterboxWidth * _spadScale.y);

    // Texture sample
    float3 rgb = tex2Dgrad(_letterboxInput, uv, duv_dx, duv_dy).rgb;

    // Bounding
    rgb *= all(uv > 0) && all (uv < 1);

    // Comvert sRGB color (= Liner color space) because Compute Shader texture output is not converted.
    if(_isLinerColorSpace) rgb = LinearToGammaSpace(rgb);

    uint offs = (id.y * _letterboxWidth + id.x) * 3;
    _letterboxTextureBuffer[offs + 0] = rgb.r;
    _letterboxTextureBuffer[offs + 1] = rgb.g;
    _letterboxTextureBuffer[offs + 2] = rgb.b;
}


// Kernel 1
float _deltaTime;
StructuredBuffer<PoseDetection> _poseDetections;
ByteAddressBuffer _poseDetectionCount;
RWStructuredBuffer<PoseRegion> _poseRegions;

// Update PoseRegion.
[numthreads(1, 1, 1)]
void PoseRegionUpdate(uint id : SV_DispatchThreadID)
{
    uint count = _poseDetectionCount.Load(0);
    if (count <= 0) return;

    // Get pose detection result by neural network model.
    const PoseDetection pd = _poseDetections[0];

    float2 hip = pd.keyPoints[0];
    float2 shoulder = pd.keyPoints[2];

    // Rotation center point
    float2 center = hip;
    float2 roi = pd.keyPoints[1];

    // Image crop size
    float sizeX = abs(roi.x - center.x);
    float sizeY = abs(roi.y - center.y);
    float size = max(sizeX, sizeY) * 3.0;

    // Pose angle
    float target = PI * 0.5;
    const float2 up = shoulder - hip;
    float angle = atan2(-up.y, up.x) - target;

    center.y = 1 - center.y;
    PoseRegion pr = _poseRegions[0];

    // Low pass filter parameters and input vector
    const float3 lpf_params = float3(2, 1.5f, _deltaTime);
    // This frame region
    const float4 box = float4(center, size, angle);
    // Calculate PoseRegion delta with low pass filter for decrease jitter.
    pr.dBox = lpf_Step_dx(box, pr.box, pr.dBox, lpf_params);
    // Calculate PoseRegion with low pass filter for decrease jitter.
    pr.box = lpf_Step_x(box, pr.box, pr.dBox, lpf_params);

    // Region crop matrix update
    float4x4 m1 = makeTranslationMatrix(pr.box.xy - pr.box.z / 2);
    float4x4 m2 = makeScalingMatrix(pr.box.z);
    float4x4 m3 = makeTranslationMatrix(0.5);
    float4x4 m4 = makeRotationMatrix(pr.box.w);
    float4x4 m5 = makeTranslationMatrix(-0.5);
    pr.cropMatrix = mul(mul(mul(mul(m1, m2), m3), m4), m5);

    _poseRegions[0] = pr;
}


// Kernel 2
#define CROP_IMAGE_SIZE 256

sampler2D _inputTexture;
StructuredBuffer<PoseRegion> _cropRegion;
RWStructuredBuffer<float> _cropedTextureBuffer;

// Crop image from PoseRegion.
[numthreads(8, 8, 1)]
void CropImage(uint2 id : SV_DispatchThreadID)
{
    float4x4 xform = _cropRegion[0].cropMatrix;

    // UV coordinates
    float2 uv = float2(0.5 + id.x, CROP_IMAGE_SIZE - 0.5 - id.y) / CROP_IMAGE_SIZE;
    uv = mul(xform, float4(uv, 0, 1)).xy;

    // De-letterboxing
    uv = (uv - 0.5) * _spadScale + 0.5;

    // UV gradients
    float2 duv_dx = mul(xform, float4(1.0 / CROP_IMAGE_SIZE, 0, 0, 0)).xy;
    float2 duv_dy = mul(xform, float4(0, -1.0 / CROP_IMAGE_SIZE, 0, 0)).xy;

    // Texture sample
    float3 rgb = tex2Dgrad(_inputTexture, uv, duv_dx, duv_dy).rgb;

    // Comvert sRGB color (= Liner color space) because Compute Shader texture output is not converted.
    if(_isLinerColorSpace) rgb = LinearToGammaSpace(rgb);

    uint offs = (id.y * CROP_IMAGE_SIZE + id.x) * 3;
    _cropedTextureBuffer[offs + 0] = rgb.r;
    _cropedTextureBuffer[offs + 1] = rgb.g;
    _cropedTextureBuffer[offs + 2] = rgb.b;
}


// Kernel 3

#define LPF_WINDOW_MAX_COUNT 5

uint _isWorldProcess;
uint _keypointCount;
float _postDeltatime;
uint _rvfWindowCount;

StructuredBuffer<float4> _postInput;
StructuredBuffer<PoseRegion> _postRegion;

RWStructuredBuffer<float> _postRvfWindowBuffer;
RWStructuredBuffer<float3> _postLastValueScale;
RWStructuredBuffer<float4> _postOutput;

// Map pose landmark to cordinates on the original input image.
[numthreads(33 + 1, 1, 1)]
void PostProcess(uint id : SV_DispatchThreadID)
{
    const float VELOCITY_SCALE = 0.1f;

    if(id > _keypointCount) return;

    if(id == _keypointCount){
        // Set human exist score in last index.
        _postOutput[id] = _postInput[_keypointCount];
    }
    else{
        // Process for normalized landmark
        PoseRegion region = _postRegion[0];
        // Visiblity of pose landmark
        float score = _postInput[id].w;
        // Pose landmark
        float3 x = _postInput[id].xyz;
        // Pose landmark on previous frame
        float3 p_x = _postOutput[id].xyz;
        // previous value scale for relative velocity filter
        float3 p_value_scale = _postLastValueScale[id];

        if(_isWorldProcess){
            x = mul(makeRotationMatrix(region.box.w), float4(x, 1)).xyz;
        }
        else{
            // Map to cordinates of letter-box image from croped image.
            x = mul(region.cropMatrix, float4(x, 1)).xyz;
            // Map to cordinates of original input image from letter-box image.
            x.xy = (x.xy - 0.5) * _spadScale + 0.5;
        }

        // Apply relative velocity filter
        // reference: 
        // https://github.com/asus4/tf-lite-unity-sample/blob/26e49bf4a45a550f84f12635a97102a3e207009e/Packages/com.github.asus4.mediapipe/Runtime/RelativeVelocityFilter.cs
        float min_x = _postInput[0].x;
        float max_x = _postInput[0].x;
        float min_y = _postInput[0].y;
        float max_y = _postInput[0].y;
        for(uint k = 0; k < _keypointCount; k++){
            if(min_x > _postInput[k].x) min_x = _postInput[k].x;
            if(max_x < _postInput[k].x) max_x = _postInput[k].x;
            if(min_y > _postInput[k].y) min_y = _postInput[k].y;
            if(max_y < _postInput[k].y) max_y = _postInput[k].y;
        }

        float2 size = float2(max_x - min_x, max_y - min_y);
        float3 value_scale = 1.0f / ((size.x + size.y) / 2);
        int window_size = min(_rvfWindowCount, LPF_WINDOW_MAX_COUNT);
        if(window_size > 0){
            float3 distance = x * value_scale - p_x * p_value_scale;
            float3 distance_sum = distance;
            float duration_sum = _postDeltatime;
            float duration_max = (1 + window_size) * _postDeltatime;
            
            for(int i = 0; i < window_size; i++){
                uint offs = (i * _keypointCount + id) * 4;
                float3 p_distance = float3(_postRvfWindowBuffer[offs + 0], _postRvfWindowBuffer[offs + 1], _postRvfWindowBuffer[offs + 2]);
                float p_duration = _postRvfWindowBuffer[offs + 3];
                if(duration_sum + p_duration > duration_max) break;
                distance_sum += p_distance;
                duration_sum +=p_duration;
            }

            float3 velocity = distance_sum / duration_sum;
            float3 alpha = 1.0 - 1.0 / (1.0 + VELOCITY_SCALE * abs(velocity));
            x = lerp(p_x, x, alpha);

            // window enqueue & dequeue for next frame
            if(window_size == LPF_WINDOW_MAX_COUNT){
                for(int j = 0; j < window_size - 1; j++){
                    uint offs1 = (j * _keypointCount + id) * 4;
                    uint offs2 = ((j + 1) * _keypointCount + id) * 4;
                    _postRvfWindowBuffer[offs1 + 0] = _postRvfWindowBuffer[offs2 + 0];
                    _postRvfWindowBuffer[offs1 + 1] = _postRvfWindowBuffer[offs2 + 1];
                    _postRvfWindowBuffer[offs1 + 2] = _postRvfWindowBuffer[offs2 + 2];
                    _postRvfWindowBuffer[offs1 + 3] = _postRvfWindowBuffer[offs2 + 3];
                }
                uint offs = ((window_size - 1) * _keypointCount + id) * 4;
                _postRvfWindowBuffer[offs + 0] = distance.x;
                _postRvfWindowBuffer[offs + 1] = distance.y;
                _postRvfWindowBuffer[offs + 2] = distance.z;
                _postRvfWindowBuffer[offs + 3] = _postDeltatime;
            }
            else{
                uint offs = (window_size * _keypointCount + id) * 4;
                _postRvfWindowBuffer[offs + 0] = distance.x;
                _postRvfWindowBuffer[offs + 1] = distance.y;
                _postRvfWindowBuffer[offs + 2] = distance.z;
                _postRvfWindowBuffer[offs + 3] = _postDeltatime;
            }
        }

        _postOutput[id] = float4(x, score);
        _postLastValueScale[id] = value_scale;
    }
}
